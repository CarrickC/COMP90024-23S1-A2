#COMP90024

Introduction
1. The teams should develop a Cloud-based solution that exploits cloud instances on MRC for harvesting data by mastodon, storing data by CouchDB, processing data by frontend , and visualizing data by frontend.
2. The teams are expected to have multiple instances of this harvesting application running on the MRC together with an associated CouchDB database containing the amalgamated collection of Mostodon and leveraging the MapReduce ability.
3. Teams are expected to develop a range of analytic scenarios.

Project Structure

This document provides a brief overview of the structure of this project and the purpose of each folder.

Ansible-playbook

This folder contains the Ansible Playbooks that automate the setting up and configuration of our server. These playbooks are idempotent, reusable, and modular, allowing for the setup of complex environments in a reliable and manageable way.

Backend

This directory includes the server-side logic of the application. Included API for our scenarios (sentiment analysis and toxicity analysis). 

SUDO_Data

The SUDO_Data folder is used for storing and handling SUDO data. SUDO data is crucial for system-level tasks and permissions in this project.

crawler

The "crawler" directory is dedicated to the web crawling component of this project for harvesting Mastodon data.

frontend/my-app

This is the front-end part of the application located in the "my-app" folder under the "frontend" directory. It is responsible for handling user interactions and presenting data to the users. The frontend is what the user sees and interacts with.

node_modules

This folder contains all the dependencies and sub-dependencies of the project. These are the packages that your project depends on to run correctly. They are installed through the Node Package Manager (NPM).

.DS_Store

.DS_Store is a file that stores custom attributes of its containing folder, such as the position of icons or the choice of a background image. It's created automatically by the macOS operating system.

README.md

This is the initial file that serves as an introductory and instructional guide to the project. It provides all necessary details to understand, install, and use the project.

package-lock.json

This file is automatically generated and updated by NPM. It contains the exact dependency tree installed in node_modules, ensuring that the installed dependencies remain the same on all machines the project is installed on.

package.json

This is a key file for Node.js projects, and it's necessary for managing dependencies that the project needs to run. It can also contain other metadata such as a project description, version number, and configuration data.


System deployment

The deployment portion of our project utilizes the Ansible tool. It automates the deployment process of
applications, ensuring consistency and reproducibility across various environments and platforms. Since we
need to deploy all environments and applications across four instances, Ansible reduces the risk of errors and
enhances efficiency. In addition, Ansible can automate various tasks such as updating software packages,
restarting services, running shell commands, and more. Following is the Ansible playbook for this project:
![image](https://github.com/CarrickC/COMP90024-23S1-A2/assets/131973111/0ff74b36-d9c2-4434-b2e2-da1471f0e517)

Figure : The overview of Ansible playbook
1. Establish four new instances, each with the appropriate selection of storage volume and security
groups.
2. Mounting and configuration of storage volumes on the relative instances.
3. Clone the necessary script files from GitHub, such as Dockerfiles and YAML files.
4. Install required dependencies and software packages, including but not limited to pip and Docker.
5. Deploy and configure CouchDB within Docker on instances 2, 3, and 4, designating instance 4 as the
master node, and integrate the remaining instances into the CouchDB cluster.
6. Deploy the Mastodon harvest within Docker on instance 4.
7. Deploy data analytics scripts (for example, sentiment analysis) and the backend infrastructure within
Docker on instance 1.
8. Implement Docker Swarm, designating instance 1 as the manager and instances 2, 3, and 4 as workers.
Utilize Docker Swarm to create a frontend service.
To see our project visualization
View http://172.26.133.136:8081![image](https://github.com/CarrickC/COMP90024-23S1-A2/assets/131973111/03b421da-9355-4aee-a584-cd274da5def1)
